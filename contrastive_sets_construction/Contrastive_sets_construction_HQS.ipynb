{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "from scispacy.linking import EntityLinker\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "aug = naw.BackTranslationAug()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "with open(\"train_HQS.txt\", 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        for m in patientDict[\"1_medical\"]:\n",
    "            s.add(m)\n",
    "        for m in patientDict[\"2_medical\"]:\n",
    "            s.add(m)\n",
    "\n",
    "with open(\"validation_HQS.txt\", 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        for m in patientDict[\"1_medical\"]:\n",
    "            s.add(m)\n",
    "        for m in patientDict[\"2_medical\"]:\n",
    "            s.add(m)\n",
    "            \n",
    "with open(\"test_HQS.txt\", 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        for m in patientDict[\"1_medical\"]:\n",
    "            s.add(m)\n",
    "        for m in patientDict[\"2_medical\"]:\n",
    "            s.add(m)\n",
    "\n",
    "ALL_medical_term = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_medical_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive set only 234\n",
    "\n",
    "path_train, path_base, count, no_type1, no_type2 = \"train_HQS.txt\", \"Positive/\", 0, set(), set()\n",
    "with open(path_train, 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        path_id = path_base + str(count) + \"/\"\n",
    "        idx = count\n",
    "        count += 1\n",
    "        if not os.path.exists(path_id): os.makedirs(path_id)\n",
    "            \n",
    "        #1: the reference summary itself is truthful\n",
    "        if len(patientDict[\"1_medical\"]) == 0:\n",
    "            with open(path_id + \"positive1.txt\", 'w') as test_file:\n",
    "                test_file.write(patientDict[\"summary\"].strip())\n",
    "        else:\n",
    "            no_type1.add(idx)\n",
    "        \n",
    "        #2: extract another utterance with using the last medical term (the last one in \"2_medical\")\n",
    "        if len(patientDict[\"2_medical\"]) > 0:\n",
    "            target_term = patientDict[\"2_medical\"][-1].lower()\n",
    "            doc = nlp(patientDict[\"question\"])\n",
    "            sent_list = list(doc.sents)\n",
    "            for i in range(len(sent_list)-1, -1, -1):\n",
    "                if target_term in str(sent_list[i]).lower() or singularize(target_term) in str(sent_list[i]).lower():\n",
    "                    with open(path_id + \"positive2.txt\", 'w') as test_file:\n",
    "                        test_file.write(str(sent_list[i]).strip())\n",
    "                    break\n",
    "                #no_type2.add(idx)\n",
    "        else:\n",
    "            no_type2.add(idx)\n",
    "\n",
    "\n",
    "        \n",
    "#3: extract the longest sentence for any training instances without positive2\n",
    "count = 0\n",
    "with open(path_train, 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        idx = count\n",
    "        path_id = path_base + str(count) + \"/\"\n",
    "        count += 1\n",
    "        if idx in no_type2:\n",
    "            doc = nlp(patientDict[\"question\"])\n",
    "            sent_list = list(doc.sents)\n",
    "            max_len, max_idx = 0, -1\n",
    "            for i in range(len(sent_list)-1, -1, -1):\n",
    "                if \"[name]\" in str(sent_list[i]).lower():\n",
    "                    continue \n",
    "                if \"[contact]\" in str(sent_list[i]).lower():\n",
    "                    continue\n",
    "                if \"[location]\" in str(sent_list[i]).lower():\n",
    "                    continue\n",
    "                if len(str(sent_list[i]).strip()) >= max_len:\n",
    "                    max_idx = i\n",
    "                    max_len = len(str(sent_list[i]).strip())\n",
    "            with open(path_id + \"positive3.txt\", 'w') as test_file:\n",
    "                test_file.write(str(sent_list[max_idx]).strip())\n",
    "        \n",
    "        #4: if reference summary is unfaithful, machine translation to perform data augmentation on #2 or #3\n",
    "        if idx in no_type1:\n",
    "            target_eg = \"\"\n",
    "            if idx not in no_type2:\n",
    "                with open(path_id + \"positive2.txt\", 'r', encoding='utf8') as f:\n",
    "                    target_eg = f.readlines()[0]\n",
    "            else:\n",
    "                with open(path_id + \"positive3.txt\", 'r', encoding='utf8') as f:\n",
    "                    target_eg = f.readlines()[0]\n",
    "            if target_eg == \"\":\n",
    "                print(\"empty target:\", idx)\n",
    "                \n",
    "            augmented_data = aug.augment(target_eg)[0]\n",
    "            with open(path_id + \"positive4.txt\", 'w') as test_file:\n",
    "                test_file.write(augmented_data.strip())\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative set only 234\n",
    "\n",
    "path_train, path_base, count = \"train_HQS.txt\", \"Negative/\", 0\n",
    "with open(path_train, 'r') as input:\n",
    "    for jsonObj in input:\n",
    "        patientDict = json.loads(jsonObj)\n",
    "        path_id = path_base + str(count) + \"/\"\n",
    "        if not os.path.exists(path_id): os.makedirs(path_id)\n",
    "        \n",
    "        #1: the reference summary itself is untruthful\n",
    "        if len(patientDict[\"1_medical\"]) > 0:\n",
    "            with open(path_id + \"negative1.txt\", 'w') as test_file:\n",
    "                test_file.write(patientDict[\"summary\"].strip())\n",
    "                \n",
    "        #2: change 1 truthful medical term (the 1st one in \"2_medical\") to another untruthful one\n",
    "        if len(patientDict[\"2_medical\"]) + len(patientDict[\"1_medical\"]) > 0:\n",
    "            truthful_medical_list, random_idx = patientDict[\"2_medical\"] + patientDict[\"1_medical\"], random.randint(0, 1547)\n",
    "            while ALL_medical_term[random_idx] in truthful_medical_list:\n",
    "                random_idx = random.randint(0, 1547)\n",
    "\n",
    "            modified_summary = patientDict[\"summary\"].replace(truthful_medical_list[0], ALL_medical_term[random_idx])\n",
    "            with open(path_id + \"negative2.txt\", 'w') as test_file:\n",
    "                test_file.write(modified_summary)\n",
    "        \n",
    "        #3: append an untruthful medical term to the start of the reference summary\n",
    "        truthful_medical_list, random_idx = patientDict[\"2_medical\"] + patientDict[\"1_medical\"], random.randint(0, 1547)\n",
    "        while ALL_medical_term[random_idx] in truthful_medical_list:\n",
    "            random_idx = random.randint(0, 1547)\n",
    "        modified_summary = ALL_medical_term[random_idx] + \" \" + patientDict[\"summary\"]\n",
    "        with open(path_id + \"negative3.txt\", 'w') as test_file:\n",
    "            test_file.write(modified_summary)\n",
    "            \n",
    "        #4: append an untruthful medical term to the END of the reference summary\n",
    "        prev_idx = random_idx\n",
    "        random_idx = random.randint(0, 1547)\n",
    "        while prev_idx == random_idx or ALL_medical_term[random_idx] in truthful_medical_list:\n",
    "            random_idx = random.randint(0, 1547)\n",
    "        modified_summary = patientDict[\"summary\"] + \" \" + ALL_medical_term[random_idx]\n",
    "        with open(path_id + \"negative4.txt\", 'w') as test_file:\n",
    "            test_file.write(modified_summary)\n",
    "            \n",
    "        #5: change numerical values\n",
    "        arabic = re.findall(r'\\d+', patientDict[\"summary\"])\n",
    "        if len(arabic) > 0:\n",
    "            modified_summary = patientDict[\"summary\"]\n",
    "            for a in arabic:\n",
    "                random_idx = random.randint(20, 30)\n",
    "                while random_idx == int(a):\n",
    "                    random_idx = random.randint(20, 30)\n",
    "                modified_summary = modified_summary.replace(a, str(random_idx))\n",
    "            \n",
    "            with open(path_id + \"negative5.txt\", 'w') as test_file:\n",
    "                test_file.write(modified_summary)\n",
    "            \n",
    "            \n",
    "        \n",
    "        #6: Swap the entities using NER\n",
    "        ent_list = list(nlp(patientDict[\"summary\"]).ents)\n",
    "        if len(ent_list) >= 2:\n",
    "            modified_summary = patientDict[\"summary\"]\n",
    "            for i in range(len(ent_list)):\n",
    "                modified_summary = modified_summary.replace(str(ent_list[i]), str(i))\n",
    "            \n",
    "            num = 0\n",
    "            for i in range(len(ent_list)-1, -1, -1):\n",
    "                modified_summary = modified_summary.replace(str(num), str(ent_list[i]))\n",
    "                num += 1\n",
    "            \n",
    "            with open(path_id + \"negative6.txt\", 'w') as test_file:\n",
    "                test_file.write(modified_summary)\n",
    "            \n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
